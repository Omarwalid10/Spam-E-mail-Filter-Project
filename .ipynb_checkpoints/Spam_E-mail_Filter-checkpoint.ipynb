{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf2858e4-1f92-4e8b-8534-5387d380fb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ilug, admin, linux, ie, mon, jul, return, pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From gort44@excite.com Mon Jun 24 17:54:21 200...</td>\n",
       "      <td>1</td>\n",
       "      <td>[gort, excite, com, mon, jun, return, path, go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From fork-admin@xent.com Mon Jul 29 11:39:57 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>[fork, admin, xent, com, mon, jul, return, pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From dcm123@btamail.net.cn Mon Jun 24 17:49:23...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dcm, btamail, net, cn, mon, jun, return, path...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ilug, admin, linux, ie, mon, aug, return, pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From tobaccodemon@terra.es Sat Sep 7 22:05:58 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[tobaccodemon, terra, e, sat, sep, return, pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From larlar78@MailOps.Com Sat Jun 30 00:19:08 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[larlar, mailops, com, sat, jun, return, path,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From rpm-list-admin@freshrpms.net Thu Jul 25 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>[rpm, list, admin, freshrpms, net, thu, jul, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From exmh-users-admin@redhat.com Wed Aug 7 06:...</td>\n",
       "      <td>0</td>\n",
       "      <td>[exmh, user, admin, redhat, com, wed, aug, ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From contractor@goldenbay.com.cy Tue Jul 23 23...</td>\n",
       "      <td>1</td>\n",
       "      <td>[contractor, goldenbay, com, cy, tue, jul, ret...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0   \n",
       "1  From gort44@excite.com Mon Jun 24 17:54:21 200...       1   \n",
       "2  From fork-admin@xent.com Mon Jul 29 11:39:57 2...       1   \n",
       "3  From dcm123@btamail.net.cn Mon Jun 24 17:49:23...       1   \n",
       "4  From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...       0   \n",
       "5  From tobaccodemon@terra.es Sat Sep 7 22:05:58 ...       1   \n",
       "6  From larlar78@MailOps.Com Sat Jun 30 00:19:08 ...       1   \n",
       "7  From rpm-list-admin@freshrpms.net Thu Jul 25 1...       0   \n",
       "8  From exmh-users-admin@redhat.com Wed Aug 7 06:...       0   \n",
       "9  From contractor@goldenbay.com.cy Tue Jul 23 23...       1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [ilug, admin, linux, ie, mon, jul, return, pat...  \n",
       "1  [gort, excite, com, mon, jun, return, path, go...  \n",
       "2  [fork, admin, xent, com, mon, jul, return, pat...  \n",
       "3  [dcm, btamail, net, cn, mon, jun, return, path...  \n",
       "4  [ilug, admin, linux, ie, mon, aug, return, pat...  \n",
       "5  [tobaccodemon, terra, e, sat, sep, return, pat...  \n",
       "6  [larlar, mailops, com, sat, jun, return, path,...  \n",
       "7  [rpm, list, admin, freshrpms, net, thu, jul, r...  \n",
       "8  [exmh, user, admin, redhat, com, wed, aug, ret...  \n",
       "9  [contractor, goldenbay, com, cy, tue, jul, ret...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics import classification_report\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"Spam_Email_Data.csv\")\n",
    "\n",
    "# Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers using regex, removing emails and html tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    # Join tokens back into a single string\n",
    "    # preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply preprocessing to the 'text' column\n",
    "data['clean_text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['clean_text'], data['target'], test_size=0.4, random_state=43)\n",
    "\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d839615e-e326-4f17-8463-a6909ee0f47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ilug-admin@linux.ie Mon Jul 29 11:28:02 2002 Return-Path: <ilug-admin@linux.ie> Delivered-To: yyyy@localhost.netnoteinc.com Received: from localhost (localhost [127.0.0.1]) by phobos.labs.netnoteinc.com (Postfix) with ESMTP id A13D94414F for <jm@localhost>; Mon, 29 Jul 2002 06:25:11 -0400 (EDT) Received: from phobos [127.0.0.1] by localhost with IMAP (fetchmail-5.9.0) for jm@localhost (single-drop); Mon, 29 Jul 2002 11:25:11 +0100 (IST) Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g6RHn7i17130 for <jm-ilug@jmason.org>; Sat, 27 Jul 2002 18:49:07 +0100 Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id SAA25016; Sat, 27 Jul 2002 18:45:03 +0100 X-Authentication-Warning: lugh.tuatha.org: Host root@localhost [127.0.0.1] claimed to be lugh Received: from mail1.mail.iol.ie (mail1.mail.iol.ie [194.125.2.192]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id SAA24977 for <ilug@linux.ie>; Sat, 27 Jul 2002 18:44:56 +0100 Received: from dialup125-a.ts551.cwt.esat.net ([193.203.140.125] helo=Hobbiton.cod.ie) by mail1.mail.iol.ie with esmtp (Exim 3.35 #1) id 17YVVF-0001W4-00 for ilug@linux.ie; Sat, 27 Jul 2002 18:37:18 +0100 Received: (from cdaly@localhost) by Hobbiton.cod.ie (8.11.6/8.9.3) id g6RDRoO04681 for ilug@linux.ie; Sat, 27 Jul 2002 14:27:50 +0100 Date: Sat, 27 Jul 2002 14:27:49 +0100 From: Conor Daly <conor.daly@oceanfree.net> To: ILUG main list <ilug@linux.ie> Subject: Re: [ILUG] Architecture crossover trouble w RH7.2 (solved) Message-Id: <20020727142749.B4438@Hobbiton.cod.ie> Mail-Followup-To: ILUG main list <ilug@linux.ie> References: <0D443C91DCE9CD40B1C795BA222A729E018854FA@milexc01.maxtor.com> MIME-Version: 1.0 Content-Type: text/plain; charset=us-ascii Content-Disposition: inline User-Agent: Mutt/1.2.5i In-Reply-To: <0D443C91DCE9CD40B1C795BA222A729E018854FA@milexc01.maxtor.com>; from conor_wynne@maxtor.com on Fri, Jul 26, 2002 at 03:56:22PM +0100 Sender: ilug-admin@linux.ie Errors-To: ilug-admin@linux.ie X-Mailman-Version: 1.1 Precedence: bulk List-Id: Irish Linux Users' Group <ilug.linux.ie> X-Beenthere: ilug@linux.ie On Fri, Jul 26, 2002 at 03:56:22PM +0100 or so it is rumoured hereabouts, Wynne, Conor thought: > Surely it would be faster to save you conf files, install it on the box > again, copy back you confs and voila. > All you car about are the confs as the boite has no DATA right? Yeah, but then I'd have to remember _exactly_ which confs I'd modified and they're not all in /etc either... > Thats what I would do, but you sysadmins have to make life as difficult & > complicated as possible ;--) Yup... In this case, I had two issues. 1. I mirrored the disk to give to someone else to work on but the box he has available has only a P1 or P2 processor. 2. My celeron box has been crashing the backup software so I wanted to try out the backup in a different box to make sure it's hardware related. Again, it's also an interesting exercise... > Have you thought about mirroring the system drives? Might save you serious > hassle down the line. Oh, I'm doing that too. This is going to Africa so I'm aiming for as robust as possible with belt, braces and probably an all-in-one jumpsuit! I'll be mirroring the disk but that is worth only so much (eg. lightning strike taking out the disk(s) or system compromise) I'm also going for a backup to CDR with an automated restore http://www.mondorescue.org . The admin out there wouldn't be able to build the system again if the mobo got fried and the replacement was the wrong arch but an i386 compatible install will mean just dropping in the HD and booting (ish)... Conor -- Conor Daly <conor.daly@oceanfree.net> Domestic Sysadmin :-) --------------------- Faenor.cod.ie 2:32pm up 64 days, 23:49, 0 users, load average: 0.00, 0.00, 0.00 Hobbiton.cod.ie 2:19pm up 7 days, 20:56, 1 user, load average: 0.05, 0.02, 0.00 -- Irish Linux Users' Group: ilug@linux.ie http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information. List maintainer: listmaster@linux.ie\n",
      "----------------------------\n",
      "['ilug', 'admin', 'linux', 'ie', 'mon', 'jul', 'return', 'path', 'ilug', 'admin', 'linux', 'ie', 'delivered', 'yyyy', 'localhost', 'netnoteinc', 'com', 'received', 'localhost', 'localhost', 'phobos', 'lab', 'netnoteinc', 'com', 'postfix', 'esmtp', 'id', 'f', 'jm', 'localhost', 'mon', 'jul', 'edt', 'received', 'phobos', 'localhost', 'imap', 'fetchmail', 'jm', 'localhost', 'single', 'drop', 'mon', 'jul', 'ist', 'received', 'lugh', 'tuatha', 'org', 'root', 'lugh', 'tuatha', 'org', 'dogma', 'slashnull', 'org', 'esmtp', 'id', 'g', 'rhn', 'jm', 'ilug', 'jmason', 'org', 'sat', 'jul', 'received', 'lugh', 'root', 'localhost', 'lugh', 'tuatha', 'org', 'esmtp', 'id', 'saa', 'sat', 'jul', 'x', 'authentication', 'warning', 'lugh', 'tuatha', 'org', 'host', 'root', 'localhost', 'claimed', 'lugh', 'received', 'mail', 'mail', 'iol', 'ie', 'mail', 'mail', 'iol', 'ie', 'lugh', 'tuatha', 'org', 'esmtp', 'id', 'saa', 'ilug', 'linux', 'ie', 'sat', 'jul', 'received', 'dialup', 't', 'cwt', 'esat', 'net', 'helo', 'hobbiton', 'cod', 'ie', 'mail', 'mail', 'iol', 'ie', 'esmtp', 'exim', 'id', 'yvvf', 'w', 'ilug', 'linux', 'ie', 'sat', 'jul', 'received', 'cdaly', 'localhost', 'hobbiton', 'cod', 'ie', 'id', 'g', 'rdroo', 'ilug', 'linux', 'ie', 'sat', 'jul', 'date', 'sat', 'jul', 'conor', 'daly', 'conor', 'daly', 'oceanfree', 'net', 'ilug', 'main', 'list', 'ilug', 'linux', 'ie', 'subject', 'ilug', 'architecture', 'crossover', 'trouble', 'w', 'rh', 'solved', 'message', 'id', 'b', 'hobbiton', 'cod', 'ie', 'mail', 'followup', 'ilug', 'main', 'list', 'ilug', 'linux', 'ie', 'reference', 'c', 'dce', 'cd', 'b', 'c', 'ba', 'e', 'fa', 'milexc', 'maxtor', 'com', 'mime', 'version', 'content', 'type', 'text', 'plain', 'charset', 'u', 'ascii', 'content', 'disposition', 'inline', 'user', 'agent', 'mutt', 'reply', 'c', 'dce', 'cd', 'b', 'c', 'ba', 'e', 'fa', 'milexc', 'maxtor', 'com', 'conor', 'wynne', 'maxtor', 'com', 'fri', 'jul', 'pm', 'sender', 'ilug', 'admin', 'linux', 'ie', 'error', 'ilug', 'admin', 'linux', 'ie', 'x', 'mailman', 'version', 'precedence', 'bulk', 'list', 'id', 'irish', 'linux', 'user', 'group', 'ilug', 'linux', 'ie', 'x', 'beenthere', 'ilug', 'linux', 'ie', 'fri', 'jul', 'pm', 'rumoured', 'hereabouts', 'wynne', 'conor', 'thought', 'surely', 'would', 'faster', 'save', 'conf', 'file', 'install', 'box', 'copy', 'back', 'confs', 'voila', 'car', 'confs', 'boite', 'data', 'right', 'yeah', 'remember', 'exactly', 'confs', 'modified', 'etc', 'either', 'thats', 'would', 'sysadmins', 'make', 'life', 'difficult', 'complicated', 'possible', 'yup', 'case', 'two', 'issue', 'mirrored', 'disk', 'give', 'someone', 'else', 'work', 'box', 'available', 'p', 'p', 'processor', 'celeron', 'box', 'crashing', 'backup', 'software', 'wanted', 'try', 'backup', 'different', 'box', 'make', 'sure', 'hardware', 'related', 'also', 'interesting', 'exercise', 'thought', 'mirroring', 'system', 'drive', 'might', 'save', 'serious', 'hassle', 'line', 'oh', 'going', 'africa', 'aiming', 'robust', 'possible', 'belt', 'brace', 'probably', 'one', 'jumpsuit', 'mirroring', 'disk', 'worth', 'much', 'eg', 'lightning', 'strike', 'taking', 'disk', 'system', 'compromise', 'also', 'going', 'backup', 'cdr', 'automated', 'restore', 'http', 'www', 'mondorescue', 'org', 'admin', 'able', 'build', 'system', 'mobo', 'got', 'fried', 'replacement', 'wrong', 'arch', 'compatible', 'install', 'mean', 'dropping', 'hd', 'booting', 'ish', 'conor', 'conor', 'daly', 'conor', 'daly', 'oceanfree', 'net', 'domestic', 'sysadmin', 'faenor', 'cod', 'ie', 'pm', 'day', 'user', 'load', 'average', 'hobbiton', 'cod', 'ie', 'pm', 'day', 'user', 'load', 'average', 'irish', 'linux', 'user', 'group', 'ilug', 'linux', 'ie', 'http', 'www', 'linux', 'ie', 'mailman', 'listinfo', 'ilug', 'un', 'subscription', 'information', 'list', 'maintainer', 'listmaster', 'linux', 'ie']\n"
     ]
    }
   ],
   "source": [
    "print(data['text'][0])\n",
    "print('----------------------------')\n",
    "print(data['clean_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08e121b4-f5ee-4583-b3f4-5840ad6c556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Embedding Technique  Accuracy  F1-Score\n",
      "0  Logistic Regression            Word2vec  0.987495  0.987464\n",
      "1  Logistic Regression             doc2vec  0.974558  0.974477\n",
      "2  Logistic Regression        Bag of Words  0.996119  0.996117\n",
      "3  Logistic Regression              TF-IDF  0.985339  0.985254\n",
      "4        Decision Tree            Word2vec  0.974127  0.974183\n",
      "5        Decision Tree             doc2vec  0.868047  0.868377\n",
      "6        Decision Tree        Bag of Words  0.978008  0.977987\n",
      "7        Decision Tree              TF-IDF  0.978439  0.978485\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create TaggedDocument objects\n",
    "tagged_data = [TaggedDocument(words=text, tags=[str(i)]) for i, text in enumerate(data['clean_text'])]\n",
    "\n",
    "# Train Doc2Vec model\n",
    "doc2vec_model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "doc2vec_model.build_vocab(tagged_data)\n",
    "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "# Define embedding techniques\n",
    "embedding_techniques = {\n",
    "    'Word2vec': Word2Vec(sentences=data['clean_text'], vector_size=100, window=5, min_count=1, workers=4),\n",
    "    'doc2vec':doc2vec_model,\n",
    "    'Bag of Words': CountVectorizer(),\n",
    "    'TF-IDF': TfidfVectorizer()\n",
    "    \n",
    "}\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "# Function to get document embeddings for Word2vec\n",
    "def get_doc_embedding_Word2vec(tokens):\n",
    "    word_embeddings = [embedding_techniques['Word2vec'].wv[word] for word in tokens if word in embedding_techniques['Word2vec'].wv]\n",
    "    if word_embeddings:\n",
    "        doc_embedding = sum(word_embeddings) / len(word_embeddings)\n",
    "    else:\n",
    "        doc_embedding = [0] * 100  \n",
    "    return doc_embedding\n",
    "\n",
    "# Function to get document embeddings for doc2vec\n",
    "def get_doc_embedding_doc2vec(tokens):\n",
    "    return doc2vec_model.infer_vector(tokens)\n",
    "    \n",
    "\n",
    "#for Bag of Words and TF-IDF training this join the words of each email\n",
    "X_train_Joining = [' '.join(row) for row in X_train]  # Joining rows\n",
    "X_test_Joining = [' '.join(row) for row in X_test]  # Joining rows\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through classifiers and embedding techniques\n",
    "for clf_name, clf in classifiers.items():\n",
    "    for vectorizer_name, vectorizer in embedding_techniques.items():\n",
    "        if vectorizer_name == 'Word2vec':\n",
    "            X_train_vectorized = X_train.apply(get_doc_embedding_Word2vec).to_list()\n",
    "            X_test_vectorized = X_test.apply(get_doc_embedding_Word2vec).to_list()\n",
    "        elif vectorizer_name == 'doc2vec':\n",
    "            X_train_vectorized = X_train.apply(get_doc_embedding_doc2vec).to_list()\n",
    "            X_test_vectorized = X_test.apply(get_doc_embedding_doc2vec).to_list()\n",
    "        else :\n",
    "        # Vectorize the data\n",
    "            X_train_vectorized = vectorizer.fit_transform(X_train_Joining)\n",
    "            X_test_vectorized = vectorizer.transform(X_test_Joining)\n",
    "        \n",
    "        # Training\n",
    "        clf.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "        # Predictions on test set\n",
    "        predictions = clf.predict(X_test_vectorized)\n",
    "        \n",
    "        # Model evaluation\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions, average='weighted')\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Model': clf_name,\n",
    "            'Embedding Technique': vectorizer_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "\n",
    "# Create dataframe from results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print summary\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e379b20-4368-4552-838f-0230811cc69e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
